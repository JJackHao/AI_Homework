{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\Desktop\\8803_AI\\H2\\H2_M1\\.venvH2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img2text(imgUrl):\n",
    "    img_to_text_pipe = pipeline(\"image-to-text\", model=\"Salesforce/blip-image-captioning-large\")\n",
    "    text = img_to_text_pipe(imgUrl)[0][\"generated_text\"]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lenovo\\Desktop\\8803_AI\\H2\\H2_M1\\.venvH2\\Lib\\site-packages\\transformers\\generation\\utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is a man standing on the street in front of a building\n"
     ]
    }
   ],
   "source": [
    "scenario = img2text(\"2.jpg\")\n",
    "print(scenario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poemGeneration(msg):\n",
    "  client = OpenAI()\n",
    "  msg_list = [{\"role\": \"system\", \"content\": \"You are a talented poet, expanding a short sentence into a poem of fewer than 100 words.\"}]\n",
    "  msg_list.append(msg)\n",
    "\n",
    "  completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.2,\n",
    "    max_completion_tokens=200,\n",
    "    messages= msg_list\n",
    "  )\n",
    "  out_msg = completion.choices[0].message.content\n",
    "  return out_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the city's heart, where shadows meet,  \n",
      "A solitary man stands on the street.  \n",
      "Before a building, tall and grand,  \n",
      "He pauses, lost in thought, or perhaps a plan.  \n",
      "\n",
      "The world around him rushes by,  \n",
      "Yet he remains, beneath the sky.  \n",
      "His silhouette, a quiet mark,  \n",
      "Against the city's bustling arc.  \n",
      "\n",
      "What dreams or burdens does he bear,  \n",
      "In the cool, indifferent evening air?  \n",
      "A moment captured, brief and fleet,  \n",
      "A man alone, where shadows meet.  \n"
     ]
    }
   ],
   "source": [
    "msg = {\"role\": \"user\", \"content\": scenario}\n",
    "poem = poemGeneration(msg)\n",
    "print(poem)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venvH2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
